---
typora-copy-images-to: 回归
typora-root-url: 回归
---

# 回归的应用

![image-20200209105303305](image-20200209105303305.png)

# 步骤

## 第一步-Select Model

![image-20200209105753330](image-20200209105753330.png)

选定好了model之后，就有了``function set``。``w``和``b``可以是任意值。下图是一个线性model。

![image-20200209110146026](image-20200209110146026.png)

## 第二部-Goodness of Function

- 获取训练集

![image-20200209110654055](image-20200209110654055.png)

- 定义function set中function的好坏

  Loss Function即为损失函数，入参数function set中的function，输出的是function的好坏。

  ![image-20200209111146955](image-20200209111146955.png)

  

- 可以通过热力图来可视化所有的wb组合产生的function set的好坏。颜色越蓝表示数值越小也即是函数越好，颜色越红表示数值越大也就是函数越差。

  ![image-20200209111552307](image-20200209111552307.png)

## 第三步-Best Function

- 在所有function的损失函数中损失最小的那个function就是best function。然后将f展开进行公示推导。

![image-20200209113408827](image-20200209113408827.png)

- 通过Gradient Descent求解最优的wb

  只要是f是可以微分的，那么就可以通过梯度下降实现求解。

  - 对一个变量进行梯度下降求解

	![image-20200209120116257](/image-20200209120116257.png)
	
  - 对多个变量进行梯度下降求解

	![image-20200209120355182](/image-20200209120355182.png)

如果损失函数是非凸函数，在梯度下降时候，有可能会因为初始值的选择落在局部最优点。但是如果是线性回归的话，那么损失函函数一定是凸函数，换言之，只有一个全局最优点，没有局部最优点。可以见下图的右边部分。

![image-20200209120802990](/image-20200209120802990.png)

## 第四步-Error

损失函数的误差大小随着Model的阶数升高，训练集error降低，测试集error升高。会出现过拟合现象。

![image-20200209135956154](/image-20200209135956154.png)

> 要选择一个最适合的model

# Model的选择

在实际应用中，会遇到在function set选择的function在测试集上都得到不理想结果。以下图为例，可以看到数据受到物种因素的影响很大，所以要重新设计model。针对不同的物种进行拟合。

 ![image-20200209140540012](image-20200209140540012.png)

![image-20200209140848070](image-20200209140848070.png)

![image-20200209141023137](image-20200209141023137.png)

## 解决过拟合办法

-  添加正则惩罚项

![image-20200209141724371](/image-20200209141724371.png)

加入红色框中的正则项，就是在求解最优参数时候尽可能的使得w参数小。w变小后，会对输入的变化不敏感。因为输入的变化如果是a，输出的变化就是aw。w是一个很小的数，所以function set选出来的function是比较平滑的。

![image-20200209142453987](image-20200209142453987.png)

在Training上，\lambda越大误差越大，说明\lambda很小时候，主要是损失函数的前半部分占主导作用，导致过拟合。当\lambda变大时候，损失函数的右半部分占主导作用，使得w变小，阻止了原本过拟合时w过大的情况。但是误差会变大。

> 在做正则惩罚的时候是没有必要对b进行惩罚的。因为function的平滑程度是由w决定的，和b是没有关系的。